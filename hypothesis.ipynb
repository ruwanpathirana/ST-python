{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8cbe22a",
   "metadata": {},
   "source": [
    "### Check Normality Assumption\n",
    "\n",
    "H0: The data are normally distributed\n",
    "\n",
    "H1: The data are not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa1252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def check_normality(data):\n",
    "    test_stat_normality, p_value_normality=stats.shapiro(data)   #test name\n",
    "    print(\"p value:%.4f\" % p_value_normality)\n",
    "    if p_value_normality <0.05:\n",
    "        print(\"Reject null hypothesis >> The data is not normally distributed\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The data is normally distributed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f95db",
   "metadata": {},
   "source": [
    "This is Shapiro-Wilk’s W test, but we can also use Kolmogorov-Smirnov and D’Agostino and Pearson’s test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8350c",
   "metadata": {},
   "source": [
    "### Check Variance Assumption\n",
    "\n",
    "H0: The variance of the samples are same\n",
    "\n",
    "H1: The variance of the samples are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74aff042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variance_homogeneity(group1, group2):\n",
    "    test_stat_var, p_value_var= stats.levene(group1,group2)\n",
    "    print(\"p value:%.4f\" % p_value_var)\n",
    "    if p_value_var <0.05:\n",
    "        print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a480dc",
   "metadata": {},
   "source": [
    "It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). Suppose the resulting p-value of Levene’s test is less than the significance level (typically 0.05). In that case, the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances.\n",
    "\n",
    "For checking variance homogeneity, preferred Levene’s test but you can also check Bartlett’s test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4a126",
   "metadata": {},
   "source": [
    "1. Defining Hypothesis\n",
    "\n",
    "2. Assumption Check\n",
    "\n",
    "3. Selecting the Proper Test\n",
    "\n",
    "4. Decision and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16cee65",
   "metadata": {},
   "source": [
    "### Q1: t-test independent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e206c6",
   "metadata": {},
   "source": [
    "S-> Live attend\n",
    "\n",
    "A-> Recordings\n",
    "\n",
    "H₀: μₛ ≤ μₐ\n",
    "\n",
    "H₁: μₛ > μₐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f7dc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.6556\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0803\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "sync = np.array([94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2, 87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6])\n",
    "asyncr = np.array([77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2])\n",
    "check_normality(sync)\n",
    "check_normality(asyncr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb6195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.8149\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "check_variance_homogeneity(sync, asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b625ff6",
   "metadata": {},
   "source": [
    "### Test Hypothesis\n",
    "\n",
    "Since assumptions are satisfied, we can perform the parametric version of the test for 2 groups and unpaired data.(independent t-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88fb9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.00753598\n",
      "since the hypothesis is one sided >> use p_value/2 >> p_value_one_sided:0.0038\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest,p_value = stats.ttest_ind(sync,asyncr)\n",
    "print(\"p value:%.8f\" % p_value)\n",
    "print(\"since the hypothesis is one sided >> use p_value/2 >> p_value_one_sided:%.4f\" %(p_value/2))\n",
    "if p_value/2 <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e586dac1",
   "metadata": {},
   "source": [
    "Since the p value (0.0038) < 0.05 we reject H0 at 0.05 significance level. Therefore, we have enough evidence\n",
    "at 5% level of significance to conclude that average grade of the students who follow the course synchronously is higher than the students who follow the course asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab43c8",
   "metadata": {},
   "source": [
    "### ======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4912a",
   "metadata": {},
   "source": [
    "### Q2: ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd81b2e",
   "metadata": {},
   "source": [
    "H₀: μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
    "\n",
    "H₁: At least one of them is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f8164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_breast = np.array([794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7, 717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1])\n",
    "only_formula = np.array([898.8, 881.2, 940.2, 966.2, 957.5, 1061.7, 1046.2, 980.4, 895.6, 919.7, 1074.1, 952.5, 796.3, 859.6, 871.1 , 1047.5, 919.1 , 1160.5, 996.9])\n",
    "both = np.array([976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6, 805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 , 823.6, 818.7, 926.8, 791.7, 948.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cced198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.4694\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.4694\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.7973\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(only_breast)\n",
    "check_normality(only_breast)\n",
    "check_normality(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce4afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.7673\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(only_breast,only_formula,both)\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856a93a",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Since assumptions are satisfied, we can perform the parametric version of the test for more than 2 groups and unpaired data.(ANOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b6da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000000\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.f_oneway(only_breast,only_formula,both)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f578d5",
   "metadata": {},
   "source": [
    "Since the p value (0.0000) < 0.05 we reject H0 at 0.05 significance level. Therefore, it can be concluded that at least one of the groups has a different average monthly weight gain.\n",
    "\n",
    "To find which group or groups cause the difference, we need to perform a posthoc test/pairwise comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc337a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-posthocs in c:\\users\\rpath\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from scikit-posthocs) (3.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from scikit-posthocs) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from scikit-posthocs) (1.7.3)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from scikit-posthocs) (0.13.2)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from scikit-posthocs) (1.4.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from scikit-posthocs) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.20.0->scikit-posthocs) (1.16.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (3.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.3.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\rpath\\anaconda3\\lib\\site-packages (from statsmodels->scikit-posthocs) (0.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d03956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_68a55_row0_col0, #T_68a55_row0_col2, #T_68a55_row1_col1, #T_68a55_row2_col0, #T_68a55_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_68a55_row0_col1, #T_68a55_row1_col0, #T_68a55_row1_col2, #T_68a55_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_68a55\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_68a55_level0_col0\" class=\"col_heading level0 col0\" >only breast</th>\n",
       "      <th id=\"T_68a55_level0_col1\" class=\"col_heading level0 col1\" >only formula</th>\n",
       "      <th id=\"T_68a55_level0_col2\" class=\"col_heading level0 col2\" >both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_68a55_level0_row0\" class=\"row_heading level0 row0\" >only breast</th>\n",
       "      <td id=\"T_68a55_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_68a55_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_68a55_row0_col2\" class=\"data row0 col2\" >0.129454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68a55_level0_row1\" class=\"row_heading level0 row1\" >only formula</th>\n",
       "      <td id=\"T_68a55_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_68a55_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_68a55_row1_col2\" class=\"data row1 col2\" >0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68a55_level0_row2\" class=\"row_heading level0 row2\" >both</th>\n",
       "      <td id=\"T_68a55_row2_col0\" class=\"data row2 col0\" >0.129454</td>\n",
       "      <td id=\"T_68a55_row2_col1\" class=\"data row2 col1\" >0.000004</td>\n",
       "      <td id=\"T_68a55_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f1f7172040>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install scikit-posthocs\n",
    "# Pairwise T test for multiple comparisons of independent groups. May be used after a parametric ANOVA to do pairwise comparisons.\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "posthoc_df= sp.posthoc_ttest([only_breast,only_formula,both], equal_var=True, p_adjust=\"bonferroni\")  #****\n",
    "\n",
    "group_names= [\"only breast\", \"only formula\",\"both\"]  #****\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53102741",
   "metadata": {},
   "source": [
    "It can be concluded that:\n",
    "\n",
    "“only breast” is different than “only formula”\n",
    "\n",
    "“only formula” is different than both “only breast” and “both”\n",
    "\n",
    "“both” is different than “only formula”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63860f",
   "metadata": {},
   "source": [
    "### ======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6483cb",
   "metadata": {},
   "source": [
    "### Q3. Mann Whitney U\n",
    "\n",
    "H₀: μ₁≤μ₂\n",
    "\n",
    "H₁: μ₁>μ₂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "984ef609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0046\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.0005\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.5410\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "test_team=np.array([6.2, 7.1, 1.5, 2,3 , 2, 1.5, 6.1, 2.4, 2.3, 12.4, 1.8, 5.3, 3.1, 9.4, 2.3, 4.1])\n",
    "developer_team=np.array([2.3, 2.1, 1.4, 2.0, 8.7, 2.2, 3.1, 4.2, 3.6, 2.5, 3.1, 6.2, 12.1, 3.9, 2.2, 1.2 ,3.4])\n",
    "\n",
    "check_normality(test_team)\n",
    "check_normality(developer_team)\n",
    "check_variance_homogeneity(test_team, developer_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5cc694",
   "metadata": {},
   "source": [
    "There are two groups, and data is collected from different individuals, so it is not paired. However, the normality assumption is not satisfied; therefore, we need to use the nonparametric version of 2 group comparison for unpaired data: the Mann-Whitney U Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98421593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.8226\n",
      "Fail to reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest,pvalue = stats.mannwhitneyu(test_team,developer_team, alternative=\"two-sided\")\n",
    "print(\"p-value:%.4f\" % pvalue)\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c368850",
   "metadata": {},
   "source": [
    "Since the p value (0.8226) > 0.05 we do not reject H0 at 0.05 significance level. Therefore, it can be concluded that there is no significant difference between the average overwork time of the two teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526baca",
   "metadata": {},
   "source": [
    "### ======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c50ca",
   "metadata": {},
   "source": [
    "### Q4. Kruskal-Wallis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a196986",
   "metadata": {},
   "source": [
    "H₀: μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
    "\n",
    "H₁: At least one of them is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75fd7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube=np.array([1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956, 2146, 2151, 1943, 2125])\n",
    "instagram =np.array([2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340., 2349., 2241., 2396., 2244., \n",
    "2267., 2281.])\n",
    "facebook =np.array([2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178., 2113., 2048., 2443., 2265., \n",
    "2095., 2528.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7771cbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0285\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.4156\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1716\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(youtube)\n",
    "check_normality(instagram)\n",
    "check_normality(facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "734ac12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0012\n",
      "Reject null hypothesis >> The variances of the samples are different.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(youtube, instagram, facebook)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c0d476",
   "metadata": {},
   "source": [
    "The normality and variance homogeneity assumptions are not satisfied, therefore we need to use the nonparametric version of ANOVA for unpaired data (the data is collected from different sources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "050a52ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000015\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.kruskal(youtube, instagram, facebook)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067db219",
   "metadata": {},
   "source": [
    "Since the p value (0.000015) < 0.05 we reject H0 at 0.05 significance level. Therefore, it can be concluded that at least one of the average customer acquisition number is different.\n",
    "\n",
    "Since the data is not normal, the nonparametric version of posthoc test is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52cf4a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_398cc_row0_col0, #T_398cc_row1_col1, #T_398cc_row1_col2, #T_398cc_row2_col1, #T_398cc_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_398cc_row0_col1, #T_398cc_row0_col2, #T_398cc_row1_col0, #T_398cc_row2_col0 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_398cc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_398cc_level0_col0\" class=\"col_heading level0 col0\" >youtube</th>\n",
       "      <th id=\"T_398cc_level0_col1\" class=\"col_heading level0 col1\" >instagram</th>\n",
       "      <th id=\"T_398cc_level0_col2\" class=\"col_heading level0 col2\" >facebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_398cc_level0_row0\" class=\"row_heading level0 row0\" >youtube</th>\n",
       "      <td id=\"T_398cc_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_398cc_row0_col1\" class=\"data row0 col1\" >0.000010</td>\n",
       "      <td id=\"T_398cc_row0_col2\" class=\"data row0 col2\" >0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_398cc_level0_row1\" class=\"row_heading level0 row1\" >instagram</th>\n",
       "      <td id=\"T_398cc_row1_col0\" class=\"data row1 col0\" >0.000010</td>\n",
       "      <td id=\"T_398cc_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_398cc_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_398cc_level0_row2\" class=\"row_heading level0 row2\" >facebook</th>\n",
       "      <td id=\"T_398cc_row2_col0\" class=\"data row2 col0\" >0.002337</td>\n",
       "      <td id=\"T_398cc_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "      <td id=\"T_398cc_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f1f46fe880>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "posthoc_df= sp.posthoc_mannwhitney([youtube, instagram, facebook], p_adjust=\"bonferroni\")  #non para->sp.posthoc_mannwhitney\n",
    "\n",
    "group_names= [\"youtube\", \"instagram\",\"facebook\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4edd4",
   "metadata": {},
   "source": [
    "The average number of customers coming from YouTube is different than the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f2c9ec",
   "metadata": {},
   "source": [
    "### ======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cd144",
   "metadata": {},
   "source": [
    "### Q5. t-test dependent\n",
    "\n",
    "• The dependent variable must be continuous (interval/ratio)\n",
    "\n",
    "• The observations are independent of one another.\n",
    "\n",
    "• The dependent variable should be approximately normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ba272",
   "metadata": {},
   "source": [
    "H₀: μd>=0 or The true mean difference is equal to or bigger than zero.             μ(after)-μ(before)\n",
    "\n",
    "H₁: μd<0 or The true mean difference is smaller than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9ac0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_before_diet=np.array([224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227])\n",
    "test_results_after_diet=np.array([198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc2a2c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1635\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.1003\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_results_before_diet)\n",
    "check_normality(test_results_after_diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad5567",
   "metadata": {},
   "source": [
    "The data is paired since data is collected from the same individuals and assumptions are satisfied, then we can use the dependent t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e92a537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000008 one tailed p value:0.000004\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test_stat, p_value_paired = stats.ttest_rel(test_results_before_diet,test_results_after_diet)\n",
    "print(\"p value:%.6f\" % p_value_paired , \"one tailed p value:%.6f\" %(p_value_paired/2))\n",
    "if p_value_paired <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68386401",
   "metadata": {},
   "source": [
    "Since the p value (0.000008) < 0.05 we reject H0 at 0.05 significance level. Therefore, it can be concluded that there is enough evidence to conclude mean cholesterol level of patients has decreased after the diet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d85b86",
   "metadata": {},
   "source": [
    "### ======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79489d3b",
   "metadata": {},
   "source": [
    "### Q6. Wilcoxon signed-rank test\n",
    "\n",
    "Since the performance scores are obtained from the same files, the data is paired.\n",
    "\n",
    "H₀: μd>=0 or The true mean difference is equal to or bigger than zero.  (end-pie)\n",
    "\n",
    "H₁: μd<0 or The true mean difference is smaller than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170ff2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "piedpiper=np.array([4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25])\n",
    "endframe=np.array([4.27, 3.93, 4.01, 4.07, 3.87, 4. , 4. , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d332c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0304\n",
      "Reject null hypothesis >> The data is not normally distributed\n",
      "p value:0.9587\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(piedpiper)\n",
    "check_normality(endframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07066339",
   "metadata": {},
   "source": [
    "The normality assumption is not satisfied; therefore, we need to use the nonparametric version of the paired test, namely the Wilcoxon Signed Rank test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a30dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.000214 >> one_tailed_pval:0.000107\n",
      "one sided pvalue:0.000107\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test,pvalue = stats.wilcoxon(endframe,piedpiper) ##alternative default two sided\n",
    "print(\"p-value:%.6f\" %pvalue, \">> one_tailed_pval:%.6f\" %(pvalue/2))\n",
    "\n",
    "test,one_sided_pvalue = stats.wilcoxon(endframe,piedpiper, alternative=\"less\")\n",
    "print(\"one sided pvalue:%.6f\" %(one_sided_pvalue))\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to recejt null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06513c20",
   "metadata": {},
   "source": [
    "Since the p value (0.000107) < 0.05 we reject H0 at 0.05 significance level. Therefore, it can be concluded there is enough evidence to conclude that the performance of the PiedPaper is better than the EndFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f08dd888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median performance score of PiedPiper: 5.17\n",
      "Median performance score of EndFrame: 4.0\n"
     ]
    }
   ],
   "source": [
    "#my method\n",
    "import numpy as np\n",
    "\n",
    "piedpiper_median = np.median(piedpiper)\n",
    "endframe_median = np.median(endframe)\n",
    "\n",
    "print('Median performance score of PiedPiper:', piedpiper_median)\n",
    "print('Median performance score of EndFrame:', endframe_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a9ef81",
   "metadata": {},
   "source": [
    "The median performance score of PiedPiper is higher than the median performance score of EndFrame, which suggests that PiedPiper may be the better method for data compression without loss of quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474677f6",
   "metadata": {},
   "source": [
    "### ======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54235316",
   "metadata": {},
   "source": [
    "### Q7. Friedman Chi-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ff6af",
   "metadata": {},
   "source": [
    "H₀: μ₁=μ₂=μ₃ or The mean of the samples is the same.\n",
    "\n",
    "H₁: At least one of them is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0a13eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_A=np.array([89.8,89.9,88.6,88.7,89.6,89.7,89.2,89.3])\n",
    "method_B=np.array([90.0,90.1,88.8,88.9,89.9,90.0,89.0,89.2])\n",
    "method_C=np.array([91.5,90.7,90.3,90.4,90.2,90.3,90.2,90.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86380120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.3076\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0515\n",
      "Fail to reject null hypothesis >> The data is normally distributed\n",
      "p value:0.0016\n",
      "Reject null hypothesis >> The data is not normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(method_A)\n",
    "check_normality(method_B)\n",
    "check_normality(method_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f482251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1953\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(method_A, method_B, method_C)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3567a",
   "metadata": {},
   "source": [
    "There are three groups, but the normality assumption is violated. So, we need to use the nonparametric version of ANOVA for paired data since the accuracy scores are obtained from the same test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dbcd4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0015\n",
      "Reject null hypothesis\n",
      "89.35 89.49 90.49\n"
     ]
    }
   ],
   "source": [
    "test_stat,p_value = stats.friedmanchisquare(method_A,method_B, method_C)\n",
    "print(\"p value:%.4f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")\n",
    "    \n",
    "print(np.round(np.mean(method_A),2), np.round(np.mean(method_B),2), np.round(np.mean(method_C),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bfe7b",
   "metadata": {},
   "source": [
    "At this significance level, at least one of the methods has a different performance.\n",
    "\n",
    "Since the data is not normal, the nonparametric version of the posthoc test is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7c4fddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d563f_row0_col0, #T_d563f_row0_col1, #T_d563f_row1_col0, #T_d563f_row1_col1, #T_d563f_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_d563f_row0_col2, #T_d563f_row1_col2, #T_d563f_row2_col0, #T_d563f_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d563f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d563f_level0_col0\" class=\"col_heading level0 col0\" >Method A</th>\n",
       "      <th id=\"T_d563f_level0_col1\" class=\"col_heading level0 col1\" >Method B</th>\n",
       "      <th id=\"T_d563f_level0_col2\" class=\"col_heading level0 col2\" >Method C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d563f_level0_row0\" class=\"row_heading level0 row0\" >Method A</th>\n",
       "      <td id=\"T_d563f_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_d563f_row0_col1\" class=\"data row0 col1\" >0.078125</td>\n",
       "      <td id=\"T_d563f_row0_col2\" class=\"data row0 col2\" >0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d563f_level0_row1\" class=\"row_heading level0 row1\" >Method B</th>\n",
       "      <td id=\"T_d563f_row1_col0\" class=\"data row1 col0\" >0.078125</td>\n",
       "      <td id=\"T_d563f_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_d563f_row1_col2\" class=\"data row1 col2\" >0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d563f_level0_row2\" class=\"row_heading level0 row2\" >Method C</th>\n",
       "      <td id=\"T_d563f_row2_col0\" class=\"data row2 col0\" >0.023438</td>\n",
       "      <td id=\"T_d563f_row2_col1\" class=\"data row2 col1\" >0.023438</td>\n",
       "      <td id=\"T_d563f_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f1f76c2040>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([method_A, method_B, method_C]) \n",
    "posthoc_df=sp.posthoc_wilcoxon(data, p_adjust=\"holm\")\n",
    "# posthoc_df = sp.posthoc_nemenyi_friedman(data.T) ## another option for the posthoc test\n",
    "\n",
    "group_names= [\"Method A\", \"Method B\",\"Method C\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1143472",
   "metadata": {},
   "source": [
    "Method C outperformed others and achieved better accuracy scores than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ed8c7",
   "metadata": {},
   "source": [
    "### ======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29829990",
   "metadata": {},
   "source": [
    "### Q8. The goodness of Fit\n",
    "\n",
    "H₀: Gender and risk appetite are independent.\n",
    "\n",
    "H₁: Gender and risk appetite are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822076f",
   "metadata": {},
   "source": [
    "chi2 test should be used for this question. This test is known as the goodness-of-fit test. It implies that if the observed data are very close to the expected data. The assumption of this test every Ei ≥ 5 (in at least 80% of the cells) is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4042c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected frequencies:\n",
      "  [[ 43.21  24.74  28.23  32.41 101.41]\n",
      " [ 80.79  46.26  52.77  60.59 189.59]]\n",
      "degrees of freedom: 4\n",
      "test stat :7.0942\n",
      "p value:0.1310\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "obs =np.array([[53, 23, 30, 36, 88],[71, 48, 51, 57, 203]])\n",
    "chi2, p, dof, ex = chi2_contingency(obs, correction=False)\n",
    "\n",
    "print(\"expected frequencies:\\n \", np.round(ex,2))\n",
    "print(\"degrees of freedom:\", dof)\n",
    "print(\"test stat :%.4f\" % chi2)\n",
    "print(\"p value:%.4f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d531dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical stat:13.2767\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "## calculate critical stat\n",
    "\n",
    "alpha = 0.01\n",
    "df = (5-1)*(2-1)\n",
    "critical_stat = chi2.ppf((1-alpha), df)\n",
    "print(\"critical stat:%.4f\" % critical_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fcfba",
   "metadata": {},
   "source": [
    "Since p value is larger than α=0.01 ( or calculated statistic=7.0942 is smaller than the critical statistic=13.28) >> Fail to Reject H0. At this significance level, it can be concluded that gender and risk appetite are independent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
